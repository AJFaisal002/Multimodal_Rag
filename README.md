# ğŸ“„ Multimodal RAG â€” Chat with PDF

A production-ready **Multimodal Retrieval-Augmented Generation (RAG)** system that enables users to chat with PDF documents using both **text and images** as knowledge sources.

Built using modern LLM architecture and vector retrieval for grounded, source-aware question answering.

---

## ğŸš€ Features

- ğŸ“‘ Extracts structured text from PDFs
- ğŸ–¼ Extracts and processes embedded images
- âœ‚ Intelligent chunking of document content
- ğŸ¤– Text summarization using OpenAI models
- ğŸ” Multimodal semantic retrieval (text + images)
- ğŸ’¬ Conversational chat interface (Streamlit)
- ğŸ“Œ Source citation (page-level)
- ğŸ§  Vector search powered by ChromaDB
- ğŸ” Environment-safe API key management

---

## ğŸ— Architecture Overview

PDF â†’ Parsing â†’ Text & Image Extraction
â†’ Summarization
â†’ Embedding
â†’ Chroma Vector Store
â†’ Retriever
â†’ OpenAI LLM
â†’ Grounded Answer with Sources


### Core Components

- **Parser** â†’ Extracts text + images using PyMuPDF
- **Summarizer** â†’ Generates semantic summaries
- **Vector Store** â†’ Stores embeddings using ChromaDB
- **Retriever** â†’ Fetches relevant chunks
- **RAG Chain** â†’ Combines retrieved context with LLM
- **Streamlit UI** â†’ Interactive chat application

---

## ğŸ›  Tech Stack

- Python 3.10
- OpenAI API (GPT-4o-mini)
- ChromaDB
- LangChain
- Streamlit
- PyMuPDF
- Pillow

---

## ğŸ“‚ Project Structure


multimodal-rag/
â”‚
â”œâ”€â”€ app_streamlit.py # Main Streamlit application
â”œâ”€â”€ app.py # CLI version (optional)
â”œâ”€â”€ config.py # Configuration settings
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ parser.py
â”‚ â”œâ”€â”€ summarizer.py
â”‚ â”œâ”€â”€ vectorstore.py
â”‚ â”œâ”€â”€ retriever.py
â”‚ â””â”€â”€ rag_chain.py
â”‚
â”œâ”€â”€ utils/
â”‚ â””â”€â”€ image_utils.py
â”‚
â””â”€â”€ data/


---

## âš™ Installation

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/your-username/multimodal-rag.git
cd multimodal-rag
2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
3ï¸âƒ£ Create Environment File

Create a .env file in the project root:

OPENAI_API_KEY=your_api_key_here

âš  Never commit .env to GitHub.

â–¶ Running the Application
py -3.10 -m streamlit run app_streamlit.py

Then open:

http://localhost:8501

Upload a PDF and start chatting.

ğŸ§  How It Works

PDF is uploaded

Text and images are extracted

Content is chunked and summarized

Embeddings are generated

Stored in ChromaDB vector store

User query retrieves relevant chunks

LLM generates grounded response

Source pages are displayed

ğŸ” Example Use Cases

Academic paper Q&A

Research document exploration

Legal document review

Technical report summarization

Multimodal meme analysis

Content moderation research

ğŸ“ˆ Future Improvements

Streaming responses

Confidence scoring

Multi-document support

Cloud deployment

Docker containerization

Persistent user sessions

ğŸ¥ Demo

See Demo.mp4 in repository for application walkthrough.

ğŸ‘¨â€ğŸ’» Authors

Adnan Faisal
Shiti Chowdhury
Department of Computer Science and Engineering
Chittagong University of Engineering and Technology

ğŸ“œ License

This project is intended for academic and research purposes.
